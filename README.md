# ğŸ” Enhancing Federated Learning Security with Trust & Reputation Mechanisms

Federated Learning (FL) enables decentralized model training while preserving data privacy â€” ideal for sectors like healthcare and finance. But what happens when untrustworthy clients poison the process?

This project introduces a **Trust and Reputation-based approach** that extends FedAvg to dynamically **filter malicious or low-quality clients**, boosting model reliability and convergence in adversarial environments.

---

## ğŸ§  Motivation

- **Problem**: FL is vulnerable to poisoning, inference attacks, and client unreliability.
- **Impact**: Can compromise performance in critical domains like healthcare and autonomous systems.
- **Goal**: Ensure only trustworthy clients influence the global model by scoring and filtering them based on behavior.

---

## âš™ï¸ Key Features

- âœ… **Trust & Reputation Scoring**: Based on Euclidean distance from global model.
- ğŸ§¹ **Dynamic Client Filtering**: Clients with low trust (below threshold Î²) are excluded.
- ğŸ§ª **Attack Simulation**: Label-flipping adversaries introduced to validate robustness.
- ğŸ“‰ **Trust Decay**: Smooth updates over time, enabling recovery from occasional noise.

---

## ğŸ§ª Experimental Setup

- ğŸ” **Framework**: [Flower FL](https://flower.dev/) for client-server orchestration.
- ğŸ§¬ **Dataset**: [PathMNIST](https://medmnist.com/) â€” 100K+ pathology images (9-class).
- ğŸ¤– **Model**: CNN with ReLU, MaxPool, and FC layers.
- ğŸ’¥ **Attack Type**: Label flipping and gradient perturbations.

**Hyperparameters**:
- Learning Rate: `0.001` with 0.95 decay
- Batch Size: `32`
- Trust Smoothing: `Î³ = 0.8`
- Trust Threshold: `Î² = 0.6`

---

## ğŸ“ˆ Results

| Scenario              | Accuracy (%) | Observation                                  |
|-----------------------|--------------|----------------------------------------------|
| Baseline (FedAvg)     | ~80%         | Poisoned clients degraded model performance  |
| Trust-Enhanced FedAvg | ~87%         | Malicious clients filtered, improved accuracy|

### ğŸ” Additional Insights

- ğŸ“‰ **Global loss dropped** from 1.0 to near 0.02 in just 3 rounds.
- ğŸ§‘â€âš•ï¸ **Benign clients** maintained steady trust; adversaries showed steep trust decay.
- ğŸ›°ï¸ **Low overhead** in communication and computation.

---

## ğŸ“¦ System Components

- **Trust Manager**: Maintains smoothed trust scores and enforces filtering.
- **Client Reputation Module**: Computes deviation from global model post-training.
- **Enhanced Protocol**: Transmits both model weights & trust metrics.
- **Logging System**: Tracks participation status, trust evolution, and attack isolation.

---

## ğŸ”¬ Evaluation Metrics

- ğŸ”¹ Client-wise accuracy and loss
- ğŸ”¹ Global model convergence
- ğŸ”¹ Trust score evolution over time
- ğŸ”¹ Comparison under benign vs. adversarial conditions

---

## ğŸš§ Future Work

- ğŸ” Add cryptographic secure aggregation
- ğŸŒ Scale to 1000+ clients for IoT-scale simulation
- ğŸ¤– Handle adaptive adversaries and sybil attacks
- ğŸ“¡ Optimize further for edge deployments
- ğŸª Incorporate explainability into trust scores

---

## ğŸ‘¥ Team

- Gokula Chapala  
- Yasiru Karunawansa  
- Dhairya Lalwani  

ğŸ“ *Golisano College of Computing, RIT*

---

> ğŸ“ *A full technical report, attack models, plots, and implementation details are included in the `/report` folder.*
